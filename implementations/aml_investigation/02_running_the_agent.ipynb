{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Case Files and Running the Agent\n",
    "\n",
    "In Notebook 1 we explored the raw database and the `ReadOnlySqlDatabase` tool.\n",
    "Now we zoom out and ask: what problem is the agent actually solving, and how do we feed it a case?\n",
    "\n",
    "This notebook covers:\n",
    "1. The real-world AML workflow we modelled\n",
    "2. The data structures that represent a case\n",
    "3. Why the evaluation dataset has four case types and what each one tests\n",
    "4. How to generate cases from the raw data\n",
    "5. Running a single case through the agent and inspecting its output\n",
    "\n",
    "---\n",
    "\n",
    "**Prerequisites:** Complete Notebook 1 first. The database must exist at `implementations/aml_investigation/data/aml_transactions.db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2ec10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook path has been set to: /Users/amritkrishnan/src/eval-agents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from aieng.agent_evals.aml_investigation.data import (\n",
    "    CaseFile,\n",
    "    CaseRecord,\n",
    "    GroundTruth,\n",
    "    LaunderingPattern,\n",
    "    build_cases,\n",
    "    download_dataset_file,\n",
    "    normalize_transactions_data,\n",
    ")\n",
    "from aieng.agent_evals.aml_investigation.task import AmlInvestigationTask\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Setting the notebook directory to the project's root folder\n",
    "if Path(\"\").absolute().name == \"eval-agents\":\n",
    "    print(f\"Notebook path is already the root path: {Path('').absolute()}\")\n",
    "else:\n",
    "    os.chdir(Path(\"\").absolute().parent.parent)\n",
    "    print(f\"The notebook path has been set to: {Path('').absolute()}\")\n",
    "\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## 1. Our Model of the Anti-Money Laundering Investigation Workflow\n",
    "\n",
    "In practice, AML investigations at financial institutions are more complex than what we model here. What we model is the core investigative loop: a transaction gets flagged, a case is opened, an analyst investigates, and the analyst produces a written determination.\n",
    "\n",
    "In our model, the workflow has three stages.\n",
    "\n",
    "First, an external alerting system flags a transaction. This could be a rules engine, an ML model, a law enforcement referral, or a routine sampling process. The system assigns a `trigger_label` to the case, which is a short string describing why the case was opened. Crucially, this label is noisy: it may be a strong signal (e.g. `FAN-OUT`, `LAW_ENFORCEMENT_REFERRAL`) or essentially no signal at all (e.g. `QA_SAMPLE`, `RANDOM_REVIEW`).\n",
    "\n",
    "Second, the case is opened with a structured record containing: a unique `case_id`, the flagged `seed_transaction_id`, the `seed_timestamp` (which marks the end of the investigation window), and a `window_start` timestamp (which marks how far back the analyst should look). The analyst is only expected to reason about events within that window.\n",
    "\n",
    "Third, the analyst investigates by querying the transaction database, identifies whether the activity is consistent with a laundering pattern, and produces a written output: a narrative summary, a verdict (`is_laundering`), a pattern classification, and the specific transaction IDs that form the suspicious chain.\n",
    "\n",
    "The agent mirrors this structure exactly. It receives the case record as a JSON object, queries the database, and returns a structured `AnalystOutput`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 2. The Data Structures\n",
    "\n",
    "The agent's input and output are structured as Pydantic models. This allows us to enforce a schema at the model level, which simplifies prompt engineering and evaluation.\n",
    "\n",
    "**`CaseFile`** is what the agent receives. It contains only what a real analyst would be given at case open time: no ground truth, no answer.\n",
    "\n",
    "```python\n",
    "class CaseFile(BaseModel):\n",
    "    case_id: str               # unique identifier\n",
    "    seed_transaction_id: str   # the flagged transaction\n",
    "    seed_timestamp: str        # end of the investigation window\n",
    "    window_start: str          # start of the investigation window\n",
    "    trigger_label: str         # why the case was opened (may be noisy)\n",
    "```\n",
    "\n",
    "**`GroundTruth`** records what actually happened. It is never shown to the agent. It is used only by the graders during evaluation.\n",
    "\n",
    "```python\n",
    "class GroundTruth(BaseModel):\n",
    "    is_laundering: bool\n",
    "    pattern_type: LaunderingPattern    # FAN-IN, FAN-OUT, CYCLE, ..., NONE\n",
    "    pattern_description: str\n",
    "    attempt_transaction_ids: str       # comma-separated laundering chain\n",
    "```\n",
    "\n",
    "**`AnalystOutput`** is what the agent must produce. Its schema is enforced at the model level via `output_schema`.\n",
    "\n",
    "```python\n",
    "class AnalystOutput(BaseModel):\n",
    "    summary_narrative: str             # the agent's reasoning\n",
    "    is_laundering: bool\n",
    "    pattern_type: LaunderingPattern\n",
    "    pattern_description: str\n",
    "    flagged_transaction_ids: str       # the agent's identified laundering chain\n",
    "```\n",
    "\n",
    "A **`CaseRecord`** bundles `input: CaseFile` and `expected_output: GroundTruth` together. This is the unit that goes into the Langfuse dataset. The `input` field is sent to the agent; the `expected_output` field is passed to the graders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Input (what the agent sees) ---\n",
      "{\n",
      "  \"case_id\": \"demo-001\",\n",
      "  \"seed_transaction_id\": \"txn-abc\",\n",
      "  \"seed_timestamp\": \"2022-09-15T14:30:00\",\n",
      "  \"window_start\": \"2022-09-01T00:00:00\",\n",
      "  \"trigger_label\": \"QA_SAMPLE\"\n",
      "}\n",
      "\n",
      "--- Expected Output (hidden from the agent; used for grading) ---\n",
      "{\n",
      "  \"is_laundering\": true,\n",
      "  \"pattern_type\": \"FAN-OUT\",\n",
      "  \"pattern_description\": \"One source dispersing funds to many destinations.\",\n",
      "  \"attempt_transaction_ids\": \"txn-abc,txn-def,txn-ghi\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the structure manually\n",
    "example_case = CaseRecord(\n",
    "    input=CaseFile(\n",
    "        case_id=\"demo-001\",\n",
    "        seed_transaction_id=\"txn-abc\",\n",
    "        seed_timestamp=\"2022-09-15T14:30:00\",\n",
    "        window_start=\"2022-09-01T00:00:00\",\n",
    "        trigger_label=\"QA_SAMPLE\",  # low-signal: gives no hint about laundering\n",
    "    ),\n",
    "    expected_output=GroundTruth(\n",
    "        is_laundering=True,\n",
    "        pattern_type=LaunderingPattern.FAN_OUT,\n",
    "        pattern_description=\"One source dispersing funds to many destinations.\",\n",
    "        attempt_transaction_ids=\"txn-abc,txn-def,txn-ghi\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"--- Input (what the agent sees) ---\")\n",
    "print(example_case.input.model_dump_json(indent=2))\n",
    "\n",
    "print(\"\\n--- Expected Output (hidden from the agent; used for grading) ---\")\n",
    "print(example_case.expected_output.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "## 3. The Four Case Types\n",
    "\n",
    "A robust evaluation dataset needs to test more than just \"can the agent find laundering?\". We deliberately construct four case types, each probing a different failure mode.\n",
    "\n",
    "| Case type | `is_laundering` (ground truth) | `trigger_label` | What it tests |\n",
    "|---|---|---|---|\n",
    "| **True Positive** | `True` | Pattern name (e.g. `FAN-OUT`) | Can the agent correctly identify and describe a real laundering pattern? |\n",
    "| **True Negative** | `False` | Low-signal (`QA_SAMPLE`, `RANDOM_REVIEW`, ...) | Can the agent correctly clear a benign case without over-investigating? |\n",
    "| **False Positive** | `False` | High-signal (`ANOMALOUS_BEHAVIOR_ALERT`, `LAW_ENFORCEMENT_REFERRAL`, ...) | Can the agent resist a misleading trigger and avoid a false alarm? |\n",
    "| **False Negative** | `True` | Low-signal (`QA_SAMPLE`, `RANDOM_REVIEW`, ...) | Can the agent find laundering even when the trigger provides no hint? |\n",
    "\n",
    "The false positive and false negative cases are the most diagnostic. They test whether the agent can reason independently rather than follow the trigger label.\n",
    "\n",
    "### How each type is built\n",
    "\n",
    "**True Positives** are parsed from the `Patterns.txt` file in the Kaggle dataset. This file records every known laundering attempt: the accounts involved, the exact transactions, and the pattern type. The `trigger_label` is set to the pattern name, simulating an alerting system that correctly identified the behaviour.\n",
    "\n",
    "**True Negatives** sample random benign transactions from the dataset. The `trigger_label` is set to one of `QA_SAMPLE`, `RANDOM_REVIEW`, `RETROSPECTIVE_REVIEW`, or `MODEL_MONITORING_SAMPLE`, realistic labels for a routine compliance review that carries no signal about laundering.\n",
    "\n",
    "**False Positives** are built from benign accounts with an unusually high transaction volume on a single day. High volume is a common heuristic alert trigger, so these cases look suspicious at first glance. The trigger label is a high-signal label like `ANOMALOUS_BEHAVIOR_ALERT`, but the ground truth is `is_laundering=False`.\n",
    "\n",
    "**False Negatives** are taken from additional laundering attempts beyond those used as True Positives. The key difference: the `trigger_label` is swapped to a low-signal review label, removing any hint. The agent must discover the laundering through its own investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 4. Generating Case Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASES_PATH = Path(\"implementations/aml_investigation/data/aml_cases.jsonl\")\n",
    "\n",
    "ILLICIT_RATIO = \"HI\"  # \"HI\" or \"LI\"\n",
    "TRANSACTIONS_SIZE = \"Small\"  # \"Small\", \"Medium\", or \"Large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset files...\n",
      "Downloading to /Users/amritkrishnan/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Trans.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 454M/454M [00:17<00:00, 27.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /Users/amritkrishnan/.cache/kagglehub/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml/versions/8/HI-Small_Patterns.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 316k/316k [00:00<00:00, 2.44MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n",
      "Normalizing transactions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5,078,336 transactions.\n",
      "Building cases...\n",
      "Built 16 cases.\n",
      "Wrote cases to implementations/aml_investigation/data/aml_cases.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Run this cell only if cases do not exist yet.\n",
    "# It downloads the dataset from Kaggle and may take a minute if files aren't cached\n",
    "# locally.\n",
    "\n",
    "if not CASES_PATH.exists():\n",
    "    print(\"Downloading dataset files...\")\n",
    "    path_to_transactions_csv = download_dataset_file(ILLICIT_RATIO, TRANSACTIONS_SIZE, \"Trans.csv\")\n",
    "    path_to_patterns_txt = download_dataset_file(ILLICIT_RATIO, TRANSACTIONS_SIZE, \"Patterns.txt\")\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "    print(\"Normalizing transactions...\")\n",
    "    transactions_df = pd.read_csv(path_to_transactions_csv)\n",
    "    transactions_df = normalize_transactions_data(transactions_df)\n",
    "    print(f\"Loaded {len(transactions_df):,} transactions.\")\n",
    "\n",
    "    print(\"Building cases...\")\n",
    "    cases = build_cases(\n",
    "        path_to_patterns_txt,\n",
    "        transactions_df,\n",
    "        num_laundering_cases=5,\n",
    "        num_normal_cases=5,\n",
    "        num_false_negative_cases=3,\n",
    "        num_false_positive_cases=3,\n",
    "        lookback_days=10,  # how far back from the seed transaction the agent should investigate\n",
    "    )\n",
    "    print(f\"Built {len(cases)} cases.\")\n",
    "\n",
    "    CASES_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with CASES_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for record in cases:\n",
    "            f.write(record.model_dump_json() + \"\\n\")\n",
    "    print(f\"Wrote cases to {CASES_PATH}\")\n",
    "else:\n",
    "    print(f\"Cases already exist at {CASES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases loaded: 16\n"
     ]
    }
   ],
   "source": [
    "raw_cases = [json.loads(line) for line in CASES_PATH.read_text().splitlines() if line.strip()]\n",
    "cases = [CaseRecord.model_validate(raw_case) for raw_case in raw_cases]\n",
    "\n",
    "print(f\"Total cases loaded: {len(cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            case_id             trigger_label  is_laundering    pattern_type  \\\n",
      "0   e9c3510fe2d0...                 BIPARTITE           True       BIPARTITE   \n",
      "1   f44948bb7032...            SCATTER-GATHER           True  SCATTER-GATHER   \n",
      "2   b43797b38c2a...                     STACK           True           STACK   \n",
      "3   f1bdfa6ef586...                 BIPARTITE           True       BIPARTITE   \n",
      "4   fc578192593e...                   FAN-OUT           True         FAN-OUT   \n",
      "5   539b23227a56...      RETROSPECTIVE_REVIEW           True  GATHER-SCATTER   \n",
      "6   e48f6bf66254...                 QA_SAMPLE           True           STACK   \n",
      "7   1f76616bcdb2...             RANDOM_REVIEW           True  SCATTER-GATHER   \n",
      "8   9660f547d019...                    FAN-IN          False            NONE   \n",
      "9   fc239199555c...  ANOMALOUS_BEHAVIOR_ALERT          False            NONE   \n",
      "10  dfeedef53e67...                    RANDOM          False            NONE   \n",
      "11  346a4100b5a2...      RETROSPECTIVE_REVIEW          False            NONE   \n",
      "12  27f78b3f195b...             RANDOM_REVIEW          False            NONE   \n",
      "13  2dc522b55b37...                 QA_SAMPLE          False            NONE   \n",
      "14  e19fb380e1f4...   MODEL_MONITORING_SAMPLE          False            NONE   \n",
      "15  a9c3d7299f98...             RANDOM_REVIEW          False            NONE   \n",
      "\n",
      "    window_days  \n",
      "0            11  \n",
      "1            10  \n",
      "2            13  \n",
      "3             9  \n",
      "4             9  \n",
      "5            17  \n",
      "6            11  \n",
      "7             8  \n",
      "8             0  \n",
      "9             0  \n",
      "10            0  \n",
      "11            3  \n",
      "12            7  \n",
      "13            8  \n",
      "14            1  \n",
      "15            5  \n"
     ]
    }
   ],
   "source": [
    "# Summary table of all cases\n",
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"case_id\": case.input.case_id[:12] + \"...\",\n",
    "            \"trigger_label\": case.input.trigger_label,\n",
    "            \"is_laundering\": case.expected_output.is_laundering,\n",
    "            \"pattern_type\": case.expected_output.pattern_type.value,\n",
    "            \"window_days\": (pd.Timestamp(case.input.seed_timestamp) - pd.Timestamp(case.input.window_start)).days,\n",
    "        }\n",
    "        for case in cases\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_type\n",
      "True Positive     5\n",
      "True Negative     5\n",
      "False Negative    3\n",
      "False Positive    3\n"
     ]
    }
   ],
   "source": [
    "# Classify each case into one of the four types\n",
    "_LOW_SIGNAL = {\"QA_SAMPLE\", \"RANDOM_REVIEW\", \"RETROSPECTIVE_REVIEW\", \"MODEL_MONITORING_SAMPLE\"}\n",
    "_HIGH_SIGNAL = {\"ANOMALOUS_BEHAVIOR_ALERT\", \"LAW_ENFORCEMENT_REFERRAL\", \"EXTERNAL_TIP\"}\n",
    "_PATTERN_LABELS = {p.value for p in LaunderingPattern if p != LaunderingPattern.NONE}\n",
    "\n",
    "\n",
    "def classify_case(case: CaseRecord) -> str:\n",
    "    \"\"\"Classify a case record.\"\"\"\n",
    "    label = case.input.trigger_label\n",
    "    is_laundering = case.expected_output.is_laundering\n",
    "    if label in _PATTERN_LABELS and is_laundering:\n",
    "        return \"True Positive\"\n",
    "    if label in _LOW_SIGNAL and not is_laundering:\n",
    "        return \"True Negative\"\n",
    "    if (label in _HIGH_SIGNAL or label in _PATTERN_LABELS) and not is_laundering:\n",
    "        return \"False Positive\"\n",
    "    if label in _LOW_SIGNAL and is_laundering:\n",
    "        return \"False Negative\"\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "summary[\"case_type\"] = [classify_case(case) for case in cases]\n",
    "print(summary[\"case_type\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== True Positive ===\n",
      "  trigger_label : BIPARTITE\n",
      "  is_laundering : True\n",
      "  pattern_type  : BIPARTITE\n",
      "  window        : 2022-09-01T00:00:00  to  2022-09-12T09:05:00\n",
      "\n",
      "=== True Negative ===\n",
      "  trigger_label : RETROSPECTIVE_REVIEW\n",
      "  is_laundering : False\n",
      "  pattern_type  : NONE\n",
      "  window        : 2022-09-01T00:00:00  to  2022-09-04T07:42:00\n",
      "\n",
      "=== False Positive ===\n",
      "  trigger_label : FAN-IN\n",
      "  is_laundering : False\n",
      "  pattern_type  : NONE\n",
      "  window        : 2022-09-02T00:00:00  to  2022-09-02T23:59:00\n",
      "\n",
      "=== False Negative ===\n",
      "  trigger_label : RETROSPECTIVE_REVIEW\n",
      "  is_laundering : True\n",
      "  pattern_type  : GATHER-SCATTER\n",
      "  window        : 2022-09-01T00:00:00  to  2022-09-18T09:55:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print one representative example of each case type\n",
    "for case_type in [\"True Positive\", \"True Negative\", \"False Positive\", \"False Negative\"]:\n",
    "    idx = summary[summary[\"case_type\"] == case_type].index\n",
    "    if len(idx) == 0:\n",
    "        print(f\"[{case_type}] no examples in this dataset\\n\")\n",
    "        continue\n",
    "    case = cases[idx[0]]\n",
    "    print(f\"=== {case_type} ===\")\n",
    "    print(f\"  trigger_label : {case.input.trigger_label}\")\n",
    "    print(f\"  is_laundering : {case.expected_output.is_laundering}\")\n",
    "    print(f\"  pattern_type  : {case.expected_output.pattern_type.value}\")\n",
    "    print(f\"  window        : {case.input.window_start}  to  {case.input.seed_timestamp}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "source": [
    "## 5. The Agent\n",
    "\n",
    "The agent is a Google ADK `LlmAgent` configured with three things:\n",
    "\n",
    "- A detailed system prompt (`ANALYST_PROMPT`) describing the investigation workflow, a strategy for querying the database efficiently (start with aggregates, expand selectively), and the laundering typologies to look for.\n",
    "- Two tools: `get_schema_info()` and `execute(query)` from `ReadOnlySqlDatabase`, the same ones explored in Notebook 1.\n",
    "- A structured output schema that enforces `AnalystOutput`, so the final response is always a valid, parseable object.\n",
    "\n",
    "`AmlInvestigationTask` is a thin wrapper around the agent that:\n",
    "1. Serializes the `CaseFile` to JSON and sends it as the user message\n",
    "2. Streams the agent's response via the ADK runner\n",
    "3. Extracts the final response and parses it into an `AnalystOutput` object\n",
    "\n",
    "It implements the `TaskFunction` protocol expected by the Langfuse experiment harness, so it can be passed directly to `run_experiment`. We will use it that way in Notebook 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## 6. Running a Single Case\n",
    "\n",
    "Let's run one case manually and watch the agent work.\n",
    "\n",
    "> **Note:** This requires a `.env` file with valid `GOOGLE_API_KEY`, `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, and `LANGFUSE_HOST` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 01:04:52,624 WARNING opentelemetry.trace: Overriding of current TracerProvider is not allowed\n",
      "2026-02-25 01:04:52,667 INFO aieng.agent_evals.langfuse: Langfuse tracing initialized successfully (endpoint: https://us.cloud.langfuse.com/api/public/otel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent : AmlInvestigationAnalyst\n",
      "Model : gemini-2.5-pro\n",
      "Tools : ['get_schema_info', 'execute']\n"
     ]
    }
   ],
   "source": [
    "task = AmlInvestigationTask()\n",
    "print(f\"Agent : {task._agent.name}\")\n",
    "print(f\"Model : {task._agent.model}\")\n",
    "print(f\"Tools : {[tool.name for tool in task._agent.tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running case : e9c3510fe2d0136a\n",
      "  Type         : True Positive\n",
      "  Trigger      : BIPARTITE\n",
      "  Window       : 2022-09-01T00:00:00 to 2022-09-12T09:05:00\n",
      "\n",
      "--- Input sent to the agent ---\n",
      "{\n",
      "  \"case_id\": \"e9c3510fe2d0136a\",\n",
      "  \"seed_transaction_id\": \"164379a3df3ce305\",\n",
      "  \"seed_timestamp\": \"2022-09-12T09:05:00\",\n",
      "  \"window_start\": \"2022-09-01T00:00:00\",\n",
      "  \"trigger_label\": \"BIPARTITE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pick a case type to run.\n",
    "# Try all four types to see how the agent behaves on each.\n",
    "CASE_TYPE_TO_RUN = \"True Positive\"  # options: \"True Positive\", \"True Negative\", \"False Positive\", \"False Negative\"\n",
    "\n",
    "idx = summary[summary[\"case_type\"] == CASE_TYPE_TO_RUN].index\n",
    "if len(idx) == 0:\n",
    "    raise ValueError(f\"No cases of type '{CASE_TYPE_TO_RUN}' found.\")\n",
    "\n",
    "selected_case = cases[idx[0]]\n",
    "print(f\"Running case : {selected_case.input.case_id}\")\n",
    "print(f\"  Type         : {CASE_TYPE_TO_RUN}\")\n",
    "print(f\"  Trigger      : {selected_case.input.trigger_label}\")\n",
    "print(f\"  Window       : {selected_case.input.window_start} to {selected_case.input.seed_timestamp}\")\n",
    "print()\n",
    "print(\"--- Input sent to the agent ---\")\n",
    "print(selected_case.input.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 01:04:52,697 INFO google_adk.google.adk.models.google_llm: Sending out request, model: gemini-2.5-pro, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2026-02-25 01:05:03,396 INFO google_adk.google.adk.models.google_llm: Response received from the model.\n",
      "2026-02-25 01:05:03,397 WARNING google_genai.types: Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2026-02-25 01:05:03,431 INFO google_adk.google.adk.models.google_llm: Sending out request, model: gemini-2.5-pro, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2026-02-25 01:05:06,584 INFO google_adk.google.adk.models.google_llm: Response received from the model.\n",
      "2026-02-25 01:05:06,615 INFO google_adk.google.adk.models.google_llm: Sending out request, model: gemini-2.5-pro, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2026-02-25 01:05:11,021 INFO google_adk.google.adk.models.google_llm: Response received from the model.\n",
      "2026-02-25 01:05:11,054 INFO google_adk.google.adk.models.google_llm: Sending out request, model: gemini-2.5-pro, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2026-02-25 01:05:14,235 INFO google_adk.google.adk.models.google_llm: Response received from the model.\n",
      "2026-02-25 01:05:14,263 INFO google_adk.google.adk.models.google_llm: Sending out request, model: gemini-2.5-pro, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2026-02-25 01:05:20,904 INFO google_adk.google.adk.models.google_llm: Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agent Output ---\n",
      "{'summary_narrative': 'Unable to proceed with investigation due to inability to access transaction data. The database schema could not be retrieved, preventing any queries from being successfully executed. Therefore, no conclusion can be drawn about the case.', 'is_laundering': False, 'pattern_type': <LaunderingPattern.NONE: 'NONE'>, 'pattern_description': 'The investigation could not be completed as the underlying database schema could not be determined. Attempts to query for transaction data failed, and the get_schema_info() tool did not return any table information. Without access to transaction data, no analysis or determination can be made.', 'flagged_transaction_ids': ''}\n",
      "Agent finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent. This makes live LLM calls and may take 2-3 minutes.\n",
    "agent_output = await task(item={\"input\": selected_case.input.model_dump()})\n",
    "\n",
    "if agent_output is None:\n",
    "    print(\"Agent returned no output. Check your credentials and that the database exists.\")\n",
    "else:\n",
    "    print(\"\\n--- Agent Output ---\")\n",
    "    print(agent_output)\n",
    "\n",
    "    print(\"Agent finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "source": [
    "## 7. Comparing Agent Output to Ground Truth\n",
    "\n",
    "Before introducing automated graders, let's compare the output by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field                          Ground Truth              Agent Output              Match?\n",
      "------------------------------------------------------------------------------------------\n",
      "is_laundering                  True                      False                     WRONG\n",
      "pattern_type                   BIPARTITE                 NONE                      WRONG\n",
      "\n",
      "Ground truth tx IDs  : e78f2bd618017e8d,4378c657099b9d1d,620718e58baba3ce,d9245ccd60994d84,3ca0f325438e2e1c,2c958b7a50659532,89cd840dc595368f,dde7ac832e510a9a,164379a3df3ce305\n",
      "Agent flagged tx IDs : (none)\n"
     ]
    }
   ],
   "source": [
    "if agent_output is not None:\n",
    "    ground_truth = selected_case.expected_output\n",
    "\n",
    "    is_laundering_match = ground_truth.is_laundering == agent_output[\"is_laundering\"]\n",
    "    pattern_match = ground_truth.pattern_type.value == agent_output[\"pattern_type\"]\n",
    "\n",
    "    ground_truth_transaction_ids = {i.strip() for i in ground_truth.attempt_transaction_ids.split(\",\") if i.strip()}\n",
    "    agent_flagged_ids = {i.strip() for i in agent_output[\"flagged_transaction_ids\"].split(\",\") if i.strip()}\n",
    "\n",
    "    print(f\"{'Field':<30} {'Ground Truth':<25} {'Agent Output':<25} {'Match?'}\")\n",
    "    print(\"-\" * 90)\n",
    "    print(\n",
    "        f\"{'is_laundering':<30} {str(ground_truth.is_laundering):<25} {str(agent_output['is_laundering']):<25} {'OK' if is_laundering_match else 'WRONG'}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'pattern_type':<30} {ground_truth.pattern_type.value:<25} {agent_output['pattern_type'].value:<25} {'OK' if pattern_match else 'WRONG'}\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    print(f\"Ground truth tx IDs  : {ground_truth.attempt_transaction_ids or '(none)'}\")\n",
    "    print(f\"Agent flagged tx IDs : {agent_output['flagged_transaction_ids'] or '(none)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent Summary Narrative ===\n",
      "Unable to proceed with investigation due to inability to access transaction data. The database schema could not be retrieved, preventing any queries from being successfully executed. Therefore, no conclusion can be drawn about the case.\n"
     ]
    }
   ],
   "source": [
    "if agent_output is not None:\n",
    "    print(\"=== Agent Summary Narrative ===\")\n",
    "    print(agent_output[\"summary_narrative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {},
   "source": [
    "## 8. Try the Other Case Types\n",
    "\n",
    "Go back to the cell in section 6 that sets `CASE_TYPE_TO_RUN` and change it to each of the four types. A few things to pay attention to:\n",
    "\n",
    "- **False Positive**: The `trigger_label` suggests something suspicious. Does the agent correctly clear the case, or does it follow the trigger?\n",
    "- **False Negative**: The `trigger_label` is noise. Does the agent still find the laundering pattern through its own investigation?\n",
    "- **True Negative**: A completely benign case. Does the agent close it cleanly without over-reaching?\n",
    "\n",
    "In the **next** notebook, we will introduce automated graders that quantify the agent's performance across these dimensions at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277c27b1587741f2af2001be3712ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 01:05:20,926 INFO google_adk.google.adk.runners: Closing runner...\n",
      "2026-02-25 01:05:20,927 INFO google_adk.google.adk.runners: Runner closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task closed.\n"
     ]
    }
   ],
   "source": [
    "await task.close()\n",
    "print(\"Task closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
